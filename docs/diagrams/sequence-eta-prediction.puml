@startuml Sequence-ETA-Prediction
!theme plain
skinparam sequenceMessageAlign center
skinparam responseMessageBelowArrow true

title Sequence Diagram - ETA Prediction Flow

actor "Fleet Manager" as FleetMgr
participant "Web Frontend\n(Vue.js)" as Frontend
participant "Backend API\n(Go)" as Backend
database "PostgreSQL\n(TimescaleDB)" as DB
participant "ML Service\n(Python/FastAPI)" as MLService
participant "Feature Store" as FeatureStore
participant "LSTM Model\n(TensorFlow)" as LSTM
participant "Weather API\n(External)" as WeatherAPI
participant "AIS Data API\n(External)" as AISAPI
database "Redis Cache" as Cache

autonumber

== Request Phase ==

FleetMgr -> Frontend: Click "Predict ETA" for Ship ID 123
activate Frontend

Frontend -> Frontend: Validate ship selection
Frontend -> Backend: GET /api/predict/eta?shipId=123
activate Backend

Backend -> Cache: Check cached prediction\nKEY: "eta:123"
activate Cache
Cache --> Backend: Cache MISS (or expired)
deactivate Cache

== Data Retrieval Phase ==

Backend -> DB: SELECT current ship data\n(location, speed, course, destination)
activate DB
DB --> Backend: Ship data:\n{lat: -5.5, lon: 112.5, speed: 15kn,\ndestination: "Taboneo Port"}
deactivate DB

Backend -> DB: SELECT historical voyage data\n(last 24 hours AIS data)
activate DB
DB --> Backend: Time-series data:\n[{timestamp, lat, lon, speed, course}...]
deactivate DB

Backend -> DB: SELECT vessel characteristics\n(draft, tonnage, type)
activate DB
DB --> Backend: Vessel data:\n{draft: 8.5m, tonnage: 15000DWT}
deactivate DB

== ML Prediction Phase ==

Backend -> MLService: POST /predict/eta\n{\n  shipId: 123,\n  currentData: {...},\n  historicalData: [...],\n  vesselSpecs: {...}\n}
activate MLService

MLService -> MLService: Validate input data\n(schema validation, range checks)

group External Data Fetching [Parallel]
    MLService -> WeatherAPI: GET /forecast?route=...\n(origin to destination)
    activate WeatherAPI
    WeatherAPI --> MLService: Weather forecast:\n[{temp, wind_speed, wave_height}...]
    deactivate WeatherAPI

    MLService -> AISAPI: GET /traffic?area=...\n(vessel congestion data)
    activate AISAPI
    AISAPI --> MLService: Traffic density data
    deactivate AISAPI
end

== Feature Engineering Phase ==

MLService -> FeatureStore: Preprocess and engineer features
activate FeatureStore

FeatureStore -> FeatureStore: Normalize coordinates\n(lat/lon → [-1, 1])
FeatureStore -> FeatureStore: Calculate distance to destination\n(Haversine formula)
FeatureStore -> FeatureStore: Encode temporal features\n(hour_of_day, day_of_week)
FeatureStore -> FeatureStore: Weather feature extraction\n(avg wind, wave height)
FeatureStore -> FeatureStore: Create sequence tensor\nShape: (batch=1, seq=24, features=15)

FeatureStore --> MLService: Preprocessed feature tensor
deactivate FeatureStore

== Model Inference Phase ==

MLService -> LSTM: model.predict(feature_tensor)
activate LSTM

LSTM -> LSTM: Bi-LSTM forward pass\n(encode temporal patterns)
LSTM -> LSTM: Attention mechanism\n(focus on important timesteps)
LSTM -> LSTM: Dense layers\n(final prediction)

LSTM --> MLService: Prediction output:\n{\n  eta_mean: 24.5 hours,\n  eta_std: 1.2 hours,\n  confidence: 0.92\n}
deactivate LSTM

== Post-Processing Phase ==

MLService -> MLService: Calculate arrival timestamp\neta_timestamp = now + 24.5h
MLService -> MLService: Calculate confidence interval\n95% CI: [22.1h, 26.9h]
MLService -> MLService: Estimate fuel on arrival\n(based on predicted consumption rate)

MLService --> Backend: Prediction result:\n{\n  shipId: 123,\n  predictedETA: "2024-10-22T14:30:00Z",\n  confidenceScore: 0.92,\n  confidenceInterval: {...},\n  predictedFuelOnArrival: 8500L\n}
deactivate MLService

== Storage & Response Phase ==

Backend -> DB: INSERT INTO predictions\n(log prediction for monitoring)
activate DB
DB --> Backend: Prediction saved (ID: 456)
deactivate DB

Backend -> Cache: SET "eta:123" = {...}\nTTL: 300 seconds (5 min)
activate Cache
Cache --> Backend: Cache updated
deactivate Cache

Backend --> Frontend: HTTP 200 OK\n{\n  eta: "2024-10-22T14:30:00Z",\n  confidence: 0.92,\n  fuelEstimate: 8500L,\n  route: [...]\n}
deactivate Backend

== Display Phase ==

Frontend -> Frontend: Parse prediction response
Frontend -> Frontend: Update map visualization\n(show remaining route as dotted line)
Frontend -> Frontend: Display ETA with confidence\n("Arrives in 24h 30m ± 2h 24m")
Frontend -> Frontend: Show fuel gauge\n(estimated 8500L on arrival)

Frontend --> FleetMgr: Display updated dashboard\nwith ETA prediction
deactivate Frontend

== Background Task ==

note over Backend, DB
  **Background Process (Async):**
  - Track prediction accuracy when ship arrives
  - Update model performance metrics
  - Trigger retraining if accuracy drops below 90%
end note

@enduml
